{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   During data analysis, one of the early steps is cleaning our data. This process can help us avoid working with erroneous   data or outliers, which can influence and cover actual or truth values within your model and analysis. Furthermore, our data   needs to take a format in which the predictive model can accept our the data.\n",
    "\n",
    "   The cleaning process steps for this projects outlined as follow:\n",
    "\n",
    "**Data Preparation**\n",
    "\n",
    "   First, we opened libraries and packages needed, then preceded to open data files into DataFrames.\n",
    "\n",
    "\n",
    "**Bad Data and Outliers**\n",
    "\n",
    "   This project's implementation is through Random Forest and Decision Trees which are not very sensitive to outliers. However, I still wanted to do a quick Exploratory Data Analysis to see if there was anything out there that appeared to be error type data.\n",
    "\n",
    "After analysis in some key variables, we concluded that nothing was outstanding, so we moved on.\n",
    "\n",
    "\n",
    "**Housing data:**\n",
    "\n",
    "We had two different data files for housing, one consisted of the home's features, and the other contained the prices. We first attached these two data frames to their corresponding values, then filtered cells to dates between 2006 and 2009; I decided on this range by the most available weather dates in my weather data. And lastly, renamed sale dates columns and built a DateTime index for the homes.\n",
    "\n",
    "**Weather Data:**\n",
    "\n",
    "Our weather data files consisted of records from different weather stations. \n",
    "\n",
    "We filtered and subtracted the weather station which provided the best recordings available. Next, the dates were filtered to match our housing dates, and significant weather variables were subtracted.\n",
    "\n",
    "Corrupted values showed as a digit (-999), we changed them through numpy library as NaN(not a number values), then we filled them with the average values of their corresponding variables.\n",
    "\n",
    "After cleaning and building the data frames, these were joint to form a single data frame file.\n",
    "\n",
    "\n",
    "**Data Conversion to Fit Model Building:**\n",
    "\n",
    "We split the new data frame into our train and test objects. From this point, we filled our train variables' NaN values with means and modes by either being an integer or floating value. Also, for categorical variables, we built dummy columns since our model works only with numerical points, but not data types such as objects or strings.\n",
    "\n",
    "For our test data, we preceded to use the mean and mode values from our training data for any NaN value. The reason for this was the fact that we don't know if there will be something different about the new data(test) that can change the basis of our model. And finally, we reindex(transfer) the dummy variables from our training data to capture all the possible categorical columns values into our test set."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
